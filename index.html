<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>ARM-Java by ignacioarnaldo</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>ARM-Java</h1>
        <p>Java implementation of the Adaptive Regression by Mixing algorithm</p>
        <p class="view"><a href="https://github.com/ignacioarnaldo/arm-java">View the Project on GitHub <small>ignacioarnaldo/arm-java</small></a></p>
        <ul>
          <li><a href="https://github.com/ignacioarnaldo/arm-java/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/ignacioarnaldo/arm-java/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/ignacioarnaldo/arm-java">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>





<h1><a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Adaptive Regression by Mixing</h1>

<p>Adaptive Regression by Mixing (ARM) was introduced in:</p>

<p><em>Yuhong Yang: <a href="http://www.tandfonline.com/doi/abs/10.1198/016214501753168262#.VINK9HVGjUY">Adaptive Regression by Mixing.</a> Journal of American Statistical Association, 96:454, 574-588, 2001.</em></p>

<p>ARM fuses the predictions of a set of models according to an estimation of their accuracy. The fused model obtained with ARM is a linear combination of the predictions of the original models. 
This way, it is possible to fuse predictions obtained with different models and algorithms. For instance, one could combine the predictions of a Neural Network with the predictions of CART etc.</p>





<h1><a id="algorithm" class="anchor" href="#algorithm" aria-hidden="true"><span class="octicon octicon-link"></span></a>Algorithm</h1>

<p>ARM allows to fuse a set of models <b><em>M</em></b> according to an estimation of their accuracy. The fused model <b><em>z</em></b> obtained with ARM is a linear combination of the models
<img src="http://latex.codecogs.com/svg.latex?m \in M" border="0"/>. 
Given a test sample <img src="http://latex.codecogs.com/svg.latex?X_j" border="0"/>, 
the prediction <img src="http://latex.codecogs.com/svg.latex?\hat{z}_j" border="0"/> issued by the fused  model is the weighted average of model predictions<br>
<center><img src="http://latex.codecogs.com/svg.latex?\hat{z}_j=\sum_{m=1}^{o}W_m\hat{Y}_{mj}" border="0"/></center></p>

Thus, the fusion process consists of learning the weight 
<img src="http://latex.codecogs.com/svg.latex?W_m" border="0"/> 
for each model. Let 
<img src="http://latex.codecogs.com/svg.latex?r=|D|" border="0"/>
be the size of the fusion training set, and 
<img src="http://latex.codecogs.com/svg.latex?o=|$M$|" border="0"/> 
be the number of models in the ensemble. Here, we assume that the errors for each model are normally distributed. We then use the variance in these errors to identify the weights by executing the following steps:</p>

<ol>
	<li>Split 
<img src="http://latex.codecogs.com/svg.latex?D" border="0"/> 
randomly into two equally sized subsets 
<img src="http://latex.codecogs.com/svg.latex?D^{(1)} \text{ and } D^{(2)}" border="0"/></li>
	<li>For each model <b><em>m</em></b>, evaluate 
<img src="http://latex.codecogs.com/svg.latex?\sigma_m^2" border="0"/> 
which is the maximum likelihood estimate of the variance of the errors 
<img src="http://latex.codecogs.com/svg.latex?\overline{e}_{m} \text{ on } D^{(1)}" border="0"/> <br>
<center><img src="http://latex.codecogs.com/svg.latex?\overline{e}_{m}=\{\hat{Y}_{mj}-Y_j|\overline{X_j},Y_j \in D_{f}^{(1)}\}} " border="0"/></center>
Compute the sum of squared errors on 
<img src="http://latex.codecogs.com/svg.latex?D^{(2)}" border="0"/> <br>
<center><img src="http://latex.codecogs.com/svg.latex?\beta_m= \sum_{j=\frac{r}{2}+1}^r(\hat{Y_{mj}}-Y_j)^2" border="0"/></center></li>
	<li>Estimate the weights using:<br>
<center><img src="http://latex.codecogs.com/svg.latex?$W_m=\frac{(\sigma_m)^{-r/2} exp(-\sigma_m^{-2}{\beta_m/2})}{\sum_{j=1}^{o}(\sigma_j)^{-r/2}exp(-\sigma_j^{-2}{\beta_j/2})}$" border="0"/> </center>
	</li>

	<li>Repeat steps 1-3 for a fixed number of times. Average the weights from each iteration to get the final
  weights for the models.</li>

</ol>


<p>Transformation for large <b><em>r</em></b>: for large values of <b><em>r</em></b>, the calculation of the weights encounters an underflow error. To avoid this problem we equivalently compute the weights using:</p>
<center><img src="http://latex.codecogs.com/svg.latex?A_m=-\frac{r}{2}log(\sigma_m) + \frac{{-\sigma_m}^{-2}\beta_m}{2} " border="0"/></center><br>
and <br>
<center><img src="http://latex.codecogs.com/svg.latex?W_m=exp(A_m - log(\sum_{q=1}^{o}A_q))" border="0"/></center></p>





<h1><a id="tutorial" class="anchor" href="#tutorial" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tutorial</h1>

<h3><a name="step-2-data-format" class="anchor" href="#step-2-data-format"><span class="octicon octicon-link"></span></a>Step 1: Data format</h3>

<p>Data must be provided in csv format where:
<ol>
<li>each line corresponds to an exemplar</li>
<li>each column contains the predictions of one model (procedure in the paper)</li>
<li>the target/true values are placed in the last column</li>
</ol>
Any additional line or column containing labels or nominal values needs to be removed.</p>

<h3><a name="step-1-download-the-flexgpjar-file-from-here" class="anchor" href="#step-1-download-the-jar-file-from-here"><span class="octicon 
octicon-link"></span></a>Step 2: Download the armfusion.jar file from <a href="downloads/armfusion.jar">here</a></h2>

<h3><a name="step-3-running-flexgp" class="anchor" href="#step-3-running-flexgp"><span class="octicon 
octicon-link"></span></a>Step 3: Running ARM</h3>

<p>All you need to provide is the path to your prediction matrix in csv format and the number of iterations:</p>

<pre><code>$ java -jar armfusion.jar -csv path_to_preds -iters num_iters
</code></pre>

<p>At the end of the run, the fused model is printed. Below, we show a fused model obtained by fusing 5 models:</p>
<pre><code>   0.7 * y0
+ 0.0 * y1
+ 0.1 * y2
+ 0.2 * y3
+ 0.0 * y4
</code></pre>
<p>In the example, the first model <em>y0</em> is assigned a weight of <em>0.7</em>. Models <em>y2</em> and <em>y3</em> receive the weights <em>0.1</em> and <em>0.2</em> respectively 
while the remaining <em>y1</em> and <em>y4</em> have zero weights.</p>


<h1><a id="publications" class="anchor" href="#publications" aria-hidden="true"><span class="octicon octicon-link"></span></a>Publications</h1>

<p>This implementation of ARM has been used in the following publications:</p>

<p><em>I Arnaldo, K Veeramachaneni, UM O'Reilly: <a href="http://link.springer.com/chapter/10.1007/978-3-662-44303-3_2">Flash: A GP-GPU Ensemble Learning System for Handling Large Datasets.</a>
Genetic Programming. Lecture Notes in Computer Science Volume 8599, 2014, pp 13-24.</em></p>

<p><em>Veeramachaneni, K; Arnaldo, I; Derby, O; Oâ€™Reilly, UM: <a href="http://link.springer.com/article/10.1007/s10723-014-9320-9">FlexGP: Cloud-Based Ensemble Learning with Genetic Programming for Large Regression Problems.</a> Journal of Grid Computing. November, 2014.</em></p>



<h3>
<a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Authors and Contributors</h3>

<p>This project is developed is by Ignacio Arnaldo (<a href="https://github.com/ignacioarnaldo" class="user-mention">@ignacioarnaldo</a>) of the <a href="http://groups.csail.mit.edu/EVO-DesignOpt/groupWebSite/">Any-Scale Learning For All (ALFA)</a> group at MIT. Contact us by email at <a href="mailto:iarnaldo@mit.edu">iarnaldo@mit.edu</a></p>
<center><img src="images/ALFA-logo-lousy.png" alt="ALFA" align="middle" Vspace="45"></center></p>

      </section>
    </div>
    <footer>
      <p>Project maintained by <a href="https://github.com/ignacioarnaldo">ignacioarnaldo</a></p>
      <p>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></p>
    </footer>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-57388957-1', 'auto');
  ga('send', 'pageview');

</script>

  </body>
</html>
